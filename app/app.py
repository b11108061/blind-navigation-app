
import streamlit as st
import cv2
import time
import webbrowser
from ultralytics import YOLO
import speech_recognition as sr
import pyttsx3

# åˆå§‹åŒ–æ¨¡å‹èˆ‡å¼•æ“
model = YOLO("yolov8n")  # è‡ªå‹•ä¸‹è¼‰æ¬Šé‡
engine = pyttsx3.init()


def speak(text: str):
    """
    æ’­å ±æ–‡å­—ï¼ŒåŒæ™‚åœ¨å´é‚Šæ¬„é¡¯ç¤ºã€‚
    """
    st.sidebar.write(f"ğŸ¤–: {text}")
    engine.say(text)
    engine.runAndWait()


def listen(prompt: str = "è«‹é–‹å§‹èªªè©±") -> str:
    """
    èªéŸ³éŒ„è£½ä¸¦è¾¨è­˜ã€‚
    """
    recognizer = sr.Recognizer()
    with sr.Microphone() as source:
        speak(prompt)
        audio = recognizer.listen(source)
    try:
        return recognizer.recognize_google(audio, language="zh-TW")
    except Exception:
        return "æˆ‘æ²’æœ‰è½æ¸…æ¥šï¼Œè«‹å†èªªä¸€æ¬¡ã€‚"


def build_maps_url(destination: str, transport: str) -> str:
    base = "https://www.google.com/maps/dir/?api=1"
    mode_map = {"èµ°è·¯": "walking", "å…¬è»Š": "transit", "æ·é‹": "transit"}
    tm = mode_map.get(transport, "walking")
    return f"{base}&destination={destination}&travelmode={tm}"


def main():
    st.set_page_config(page_title="æ™ºæ…§å°ç›²ç³»çµ± SmartGuide", layout="wide")
    st.title("ğŸ¤– æ™ºæ…§å°ç›²ç³»çµ± Web App")

    session = st.session_state
    session.setdefault("step", 0)
    session.setdefault("dest", "")
    session.setdefault("transport", "")
    session.setdefault("detecting", False)

    # å´é‚Šæ¬„ï¼šå°èˆª & å°è©±æ§åˆ¶
    with st.sidebar:
        st.header("å°èˆªåŠŸèƒ½ï¼ˆæ‰‹å‹•ï¼‰")
        dest_in = st.text_input("ç›®çš„åœ°", session.dest)
        transport_in = st.selectbox("äº¤é€šæ–¹å¼", ["èµ°è·¯", "å…¬è»Š", "æ·é‹"], index=["èµ°è·¯","å…¬è»Š","æ·é‹"].index(session.transport) if session.transport in ["èµ°è·¯","å…¬è»Š","æ·é‹"] else 0)
        if st.button("é–‹å§‹å°èˆª (æ‰‹å‹•)"):
            session.dest = dest_in
            session.transport = transport_in
            url = build_maps_url(dest_in, transport_in)
            webbrowser.open(url)
            speak("å·²ç‚ºæ‚¨é–‹å•Ÿ Google Maps å°èˆªï¼Œä¸¦å•Ÿç”¨æ™ºæ…§é¡é ­åµæ¸¬ã€‚")
            session.step = 1
            session.detecting = True

        st.markdown("---")
        st.header("èªéŸ³äº’å‹• (è‡ªå‹•)")
        if session.step == 0:
            # å•Ÿå‹•èªéŸ³å•è·¯æµç¨‹
            speak("æ‚¨å¥½ï¼Œæˆ‘æ˜¯æ‚¨çš„æ™ºæ…§å°ç›²åŠ©æ‰‹ã€‚è«‹å•ä»Šå¤©æƒ³è¦å»å“ªè£¡ï¼Ÿ")
            session.dest = listen()
            st.sidebar.write(f"ç›®çš„åœ° (èªéŸ³)ï¼š{session.dest}")
            speak("è«‹å•æ‚¨æƒ³ç”¨ä»€éº¼äº¤é€šå·¥å…·ï¼Ÿä¾‹å¦‚èµ°è·¯ã€å…¬è»Šæˆ–æ·é‹ã€‚")
            session.transport = listen()
            st.sidebar.write(f"äº¤é€šæ–¹å¼ (èªéŸ³)ï¼š{session.transport}")
            url = build_maps_url(session.dest, session.transport)
            webbrowser.open(url)
            speak("å·²ç‚ºæ‚¨é–‹å•Ÿ Google Maps å°èˆªï¼Œä¸¦å•Ÿç”¨æ™ºæ…§é¡é ­åµæ¸¬ã€‚")
            session.step = 1
            session.detecting = True

        if session.detecting:
            if st.button("åœæ­¢åµæ¸¬"):
                session.detecting = False

    # è‹¥å·²å•Ÿå‹•åµæ¸¬ï¼Œä½¿ç”¨ OpenCV loop
    if session.detecting:
        st.header("ğŸ” æ™ºæ…§é¡é ­å³æ™‚åµæ¸¬ (OpenCV)")
        cap = cv2.VideoCapture(0)
        FRAME_WINDOW = st.empty()
        last_spoken = time.time()
        interval = 3

        while session.detecting:
            ret, frame = cap.read()
            if not ret:
                break

            # YOLO åµæ¸¬
            results = model(frame)[0]
            height, width = frame.shape[:2]
            region_labels = {"å·¦é‚Š": [], "ä¸­é–“": [], "å³é‚Š": []}
            for box in results.boxes:
                cls_id = int(box.cls[0])
                label = results.names[cls_id]
                x1, y1, x2, y2 = map(int, box.xyxy[0])
                cx = (x1 + x2) // 2
                region = "å·¦é‚Š" if cx < width/3 else ("ä¸­é–“" if cx < 2*width/3 else "å³é‚Š")
                region_labels[region].append(label)
                # ç•«æ¡†å’Œæ¨™ç±¤
                cv2.rectangle(frame, (x1, y1), (x2, y2), (0,255,0), 2)
                cv2.putText(frame, label, (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0,255,0), 2)

            # æ¯éš” interval æ’­å ±
            if time.time() - last_spoken > interval:
                descriptions = []
                for region, items in region_labels.items():
                    if items:
                        unique = set(items)
                        text = "ã€".join(unique)
                        if "æ–‘é¦¬ç·š" in text:
                            descriptions.append(f"{region}æ˜¯æ–‘é¦¬ç·šï¼Œè«‹æ³¨æ„éé¦¬è·¯å®‰å…¨")
                        elif "äºº" in text:
                            descriptions.append(f"{region}æœ‰äºº")
                        elif "è…³è¸è»Š" in text:
                            descriptions.append(f"{region}æœ‰è…³è¸è»Š")
                        elif "äº¤é€šç‡ˆ" in text or "traffic light" in text:
                            descriptions.append(f"{region}æ˜¯äº¤é€šç‡ˆè™Ÿï¼Œè«‹æ³¨æ„ç­‰å€™æˆ–é€šè¡Œ")
                        elif "è»Š" in text or "car" in text:
                            descriptions.append(f"{region}æœ‰è»Šè¼›ç¶“éï¼Œè«‹å°å¿ƒé€šè¡Œ")
                        elif "ç‹—" in text or "dog" in text:
                            descriptions.append(f"{region}æœ‰ç‹—")
                        elif "æ¤…å­" in text or "chair" in text:
                            descriptions.append(f"{region}æœ‰æ¤…å­")
                        elif "åƒåœ¾æ¡¶" in text or "trash can" in text:
                            descriptions.append(f"{region}æœ‰åƒåœ¾æ¡¶")
                        elif any(s in text for s in ["æ¨“æ¢¯","stair","stairs"]):
                            descriptions.append(f"{region}æ˜¯æ¨“æ¢¯ï¼Œè«‹æ³¨æ„ä¸Šä¸‹å°éšå®‰å…¨")
                        else:
                            descriptions.append(f"{region}æœ‰{text}")
                if descriptions:
                    speak("ï¼Œ".join(descriptions))
                last_spoken = time.time()

            # é¡¯ç¤ºå½±åƒ
            FRAME_WINDOW.image(frame, channels="BGR")
            # åµæ¸¬åœæ­¢æŒ‰éˆ•è·‘åœ¨åŒä¸€å´é‚Šæ¬„å³å¯è§¸ç™¼é€€å‡º
            if not session.detecting:
                break
        cap.release()

if __name__ == "__main__":
    main()

import streamlit as st
import cv2
import time
import webbrowser
from ultralytics import YOLO
import speech_recognition as sr
import pyttsx3

# åˆå§‹åŒ–æ¨¡å‹èˆ‡å¼•æ“
model = YOLO("yolov8n")  # è‡ªå‹•ä¸‹è¼‰æ¬Šé‡
engine = pyttsx3.init()


def speak(text: str):
    """
    æ’­å ±æ–‡å­—ï¼ŒåŒæ™‚åœ¨å´é‚Šæ¬„é¡¯ç¤ºã€‚
    """
    st.sidebar.write(f"ğŸ¤–: {text}")
    engine.say(text)
    engine.runAndWait()


def listen(prompt: str = "è«‹é–‹å§‹èªªè©±") -> str:
    """
    èªéŸ³éŒ„è£½ä¸¦è¾¨è­˜ã€‚
    """
    recognizer = sr.Recognizer()
    with sr.Microphone() as source:
        speak(prompt)
        audio = recognizer.listen(source)
    try:
        return recognizer.recognize_google(audio, language="zh-TW")
    except Exception:
        return "æˆ‘æ²’æœ‰è½æ¸…æ¥šï¼Œè«‹å†èªªä¸€æ¬¡ã€‚"


def build_maps_url(destination: str, transport: str) -> str:
    base = "https://www.google.com/maps/dir/?api=1"
    mode_map = {"èµ°è·¯": "walking", "å…¬è»Š": "transit", "æ·é‹": "transit"}
    tm = mode_map.get(transport, "walking")
    return f"{base}&destination={destination}&travelmode={tm}"


def main():
    st.set_page_config(page_title="æ™ºæ…§å°ç›²ç³»çµ± SmartGuide", layout="wide")
    st.title("ğŸ¤– æ™ºæ…§å°ç›²ç³»çµ± Web App")

    session = st.session_state
    session.setdefault("step", 0)
    session.setdefault("dest", "")
    session.setdefault("transport", "")
    session.setdefault("detecting", False)

    # å´é‚Šæ¬„ï¼šå°èˆª & å°è©±æ§åˆ¶
    with st.sidebar:
        st.header("å°èˆªåŠŸèƒ½ï¼ˆæ‰‹å‹•ï¼‰")
        dest_in = st.text_input("ç›®çš„åœ°", session.dest)
        transport_in = st.selectbox("äº¤é€šæ–¹å¼", ["èµ°è·¯", "å…¬è»Š", "æ·é‹"], index=["èµ°è·¯","å…¬è»Š","æ·é‹"].index(session.transport) if session.transport in ["èµ°è·¯","å…¬è»Š","æ·é‹"] else 0)
        if st.button("é–‹å§‹å°èˆª (æ‰‹å‹•)"):
            session.dest = dest_in
            session.transport = transport_in
            url = build_maps_url(dest_in, transport_in)
            webbrowser.open(url)
            speak("å·²ç‚ºæ‚¨é–‹å•Ÿ Google Maps å°èˆªï¼Œä¸¦å•Ÿç”¨æ™ºæ…§é¡é ­åµæ¸¬ã€‚")
            session.step = 1
            session.detecting = True

        st.markdown("---")
        st.header("èªéŸ³äº’å‹• (è‡ªå‹•)")
        if session.step == 0:
            # å•Ÿå‹•èªéŸ³å•è·¯æµç¨‹
            speak("æ‚¨å¥½ï¼Œæˆ‘æ˜¯æ‚¨çš„æ™ºæ…§å°ç›²åŠ©æ‰‹ã€‚è«‹å•ä»Šå¤©æƒ³è¦å»å“ªè£¡ï¼Ÿ")
            session.dest = listen()
            st.sidebar.write(f"ç›®çš„åœ° (èªéŸ³)ï¼š{session.dest}")
            speak("è«‹å•æ‚¨æƒ³ç”¨ä»€éº¼äº¤é€šå·¥å…·ï¼Ÿä¾‹å¦‚èµ°è·¯ã€å…¬è»Šæˆ–æ·é‹ã€‚")
            session.transport = listen()
            st.sidebar.write(f"äº¤é€šæ–¹å¼ (èªéŸ³)ï¼š{session.transport}")
            url = build_maps_url(session.dest, session.transport)
            webbrowser.open(url)
            speak("å·²ç‚ºæ‚¨é–‹å•Ÿ Google Maps å°èˆªï¼Œä¸¦å•Ÿç”¨æ™ºæ…§é¡é ­åµæ¸¬ã€‚")
            session.step = 1
            session.detecting = True

        if session.detecting:
            if st.button("åœæ­¢åµæ¸¬"):
                session.detecting = False

    # è‹¥å·²å•Ÿå‹•åµæ¸¬ï¼Œä½¿ç”¨ OpenCV loop
    if session.detecting:
        st.header("ğŸ” æ™ºæ…§é¡é ­å³æ™‚åµæ¸¬ (OpenCV)")
        cap = cv2.VideoCapture(0)
        FRAME_WINDOW = st.empty()
        last_spoken = time.time()
        interval = 3

        while session.detecting:
            ret, frame = cap.read()
            if not ret:
                break

            # YOLO åµæ¸¬
            results = model(frame)[0]
            height, width = frame.shape[:2]
            region_labels = {"å·¦é‚Š": [], "ä¸­é–“": [], "å³é‚Š": []}
            for box in results.boxes:
                cls_id = int(box.cls[0])
                label = results.names[cls_id]
                x1, y1, x2, y2 = map(int, box.xyxy[0])
                cx = (x1 + x2) // 2
                region = "å·¦é‚Š" if cx < width/3 else ("ä¸­é–“" if cx < 2*width/3 else "å³é‚Š")
                region_labels[region].append(label)
                # ç•«æ¡†å’Œæ¨™ç±¤
                cv2.rectangle(frame, (x1, y1), (x2, y2), (0,255,0), 2)
                cv2.putText(frame, label, (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0,255,0), 2)

            # æ¯éš” interval æ’­å ±
            if time.time() - last_spoken > interval:
                descriptions = []
                for region, items in region_labels.items():
                    if items:
                        unique = set(items)
                        text = "ã€".join(unique)
                        if "æ–‘é¦¬ç·š" in text:
                            descriptions.append(f"{region}æ˜¯æ–‘é¦¬ç·šï¼Œè«‹æ³¨æ„éé¦¬è·¯å®‰å…¨")
                        elif "äºº" in text:
                            descriptions.append(f"{region}æœ‰äºº")
                        elif "è…³è¸è»Š" in text:
                            descriptions.append(f"{region}æœ‰è…³è¸è»Š")
                        elif "äº¤é€šç‡ˆ" in text or "traffic light" in text:
                            descriptions.append(f"{region}æ˜¯äº¤é€šç‡ˆè™Ÿï¼Œè«‹æ³¨æ„ç­‰å€™æˆ–é€šè¡Œ")
                        elif "è»Š" in text or "car" in text:
                            descriptions.append(f"{region}æœ‰è»Šè¼›ç¶“éï¼Œè«‹å°å¿ƒé€šè¡Œ")
                        elif "ç‹—" in text or "dog" in text:
                            descriptions.append(f"{region}æœ‰ç‹—")
                        elif "æ¤…å­" in text or "chair" in text:
                            descriptions.append(f"{region}æœ‰æ¤…å­")
                        elif "åƒåœ¾æ¡¶" in text or "trash can" in text:
                            descriptions.append(f"{region}æœ‰åƒåœ¾æ¡¶")
                        elif any(s in text for s in ["æ¨“æ¢¯","stair","stairs"]):
                            descriptions.append(f"{region}æ˜¯æ¨“æ¢¯ï¼Œè«‹æ³¨æ„ä¸Šä¸‹å°éšå®‰å…¨")
                        else:
                            descriptions.append(f"{region}æœ‰{text}")
                if descriptions:
                    speak("ï¼Œ".join(descriptions))
                last_spoken = time.time()

            # é¡¯ç¤ºå½±åƒ
            FRAME_WINDOW.image(frame, channels="BGR")
            # åµæ¸¬åœæ­¢æŒ‰éˆ•è·‘åœ¨åŒä¸€å´é‚Šæ¬„å³å¯è§¸ç™¼é€€å‡º
            if not session.detecting:
                break
        cap.release()

if __name__ == "__main__":
    main()

